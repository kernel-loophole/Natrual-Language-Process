{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yLDi-9C3hpWy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train =np.array([[0, 0],[0,1],[1,0],[1,1]])\n",
        "y_train =np.array([[0],[1],[1],[0]])\n"
      ],
      "metadata": {
        "id": "sCOq7OkkjtD6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "num_neurons = 10\n",
        "model.add(Dense(num_neurons, input_dim=2))\n",
        "model.add(Activation('tanh'))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.summary()\n",
        "#Some quick math: 10 neurons, each with two\n",
        "#weights (one for each value in the input vector), and one weight for the bias gives you\n",
        "#30 weights to learn.\n",
        "#10*2+10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnrDBdaaj6-a",
        "outputId": "e91a7fa7-fb46-4fd5-a180-f4c6d09d289b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 10)                30        \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41\n",
            "Trainable params: 41\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = SGD(lr=0.1)\n",
        "model.compile(loss='binary_crossentropy', optimizer=sgd,\n",
        "metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdejmDP8kfad",
        "outputId": "37c09314-a6be-4323-d8ac-cb700dca6a25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCmGEJ2_mYY5",
        "outputId": "cfa380f8-eb5a-4477-93cd-30e7e6ae67c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 394ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5       ],\n",
              "       [0.4526389 ],\n",
              "       [0.57300496],\n",
              "       [0.5296691 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL2hepO0mxyL",
        "outputId": "63a8f514-94f8-49fa-d39a-44ec9f038b1b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6992 - accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6988 - accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6984 - accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6979 - accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6975 - accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6971 - accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6966 - accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6962 - accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6928 - accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6924 - accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6920 - accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6916 - accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6911 - accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6907 - accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6903 - accuracy: 0.5000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6899 - accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6895 - accuracy: 0.5000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6890 - accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6886 - accuracy: 0.5000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6882 - accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6878 - accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6873 - accuracy: 0.5000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6869 - accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6861 - accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6856 - accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6852 - accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6848 - accuracy: 0.5000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6839 - accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6835 - accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6830 - accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6826 - accuracy: 0.5000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6821 - accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6817 - accuracy: 0.5000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6812 - accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6808 - accuracy: 0.5000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6803 - accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6799 - accuracy: 0.5000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6794 - accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6790 - accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6785 - accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6780 - accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6776 - accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6771 - accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6766 - accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6761 - accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6757 - accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6752 - accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6747 - accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6742 - accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6737 - accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6732 - accuracy: 0.5000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6727 - accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6722 - accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6717 - accuracy: 0.5000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6712 - accuracy: 0.5000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6707 - accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6702 - accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6697 - accuracy: 0.5000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6692 - accuracy: 0.5000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6687 - accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6681 - accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6676 - accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6671 - accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6666 - accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6660 - accuracy: 0.7500\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6655 - accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6649 - accuracy: 0.7500\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6644 - accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6638 - accuracy: 0.7500\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6633 - accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6627 - accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6622 - accuracy: 0.7500\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6616 - accuracy: 0.7500\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6610 - accuracy: 0.7500\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6604 - accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6599 - accuracy: 0.7500\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6593 - accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6587 - accuracy: 0.7500\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6581 - accuracy: 0.7500\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6575 - accuracy: 0.7500\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6569 - accuracy: 0.7500\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6563 - accuracy: 0.7500\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6557 - accuracy: 0.7500\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6551 - accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6545 - accuracy: 0.7500\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6539 - accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6532 - accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6526 - accuracy: 0.7500\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6520 - accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6514 - accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6507 - accuracy: 0.7500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc6442f1ff0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre=model.predict(x_train>0.5)\n",
        "pre"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDOaLA6pm6Iy",
        "outputId": "4e867582-a87d-4045-ef23-55461de4247c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.44703123],\n",
              "       [0.5151696 ],\n",
              "       [0.54058903],\n",
              "       [0.5178386 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_predicted = y_train[np.argmax(pre)]\n",
        "class_predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJIVEZfmnGM9",
        "outputId": "5e3eff45-8275-4e3f-e9ba-b9a4dc719e8c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_structure = model.to_json()\n",
        "with open(\"basic_model.json\", \"w\") as json_file:\n",
        "  json_file.write(model_structure)\n",
        "model.save_weights(\"basic_weights.h5\")"
      ],
      "metadata": {
        "id": "UdO8qikPpB9A"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0tra3w9KpuVw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}